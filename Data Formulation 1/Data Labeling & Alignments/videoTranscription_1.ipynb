{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvly_yyz9Eq1"
      },
      "source": [
        "## Extracting Audios From Videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuuG-J5t9Eq2",
        "outputId": "4568fe46-2dad-44a4-8f93-2664e4980a8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- Converting Video To Audio for P1_1\n",
            "MoviePy - Writing audio in ./Eye Tracker Audio Converted/transcribed_speech_P1_1.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "- Converting Video To Audio for P1_2from\n",
            "MoviePy - Writing audio in ./Eye Tracker Audio Converted/transcribed_speech_P1_2from.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "- Converting Video To Audio for P2\n",
            "MoviePy - Writing audio in ./Eye Tracker Audio Converted/transcribed_speech_P2.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "- Converting Video To Audio for P3\n",
            "MoviePy - Writing audio in ./Eye Tracker Audio Converted/transcribed_speech_P3.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "- Converting Video To Audio for P4_1\n",
            "MoviePy - Writing audio in ./Eye Tracker Audio Converted/transcribed_speech_P4_1.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "- Converting Video To Audio for P4_2\n",
            "MoviePy - Writing audio in ./Eye Tracker Audio Converted/transcribed_speech_P4_2.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                      \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "- Converting Video To Audio for P5_1\n",
            "MoviePy - Writing audio in ./Eye Tracker Audio Converted/transcribed_speech_P5_1.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "- Converting Video To Audio for P5_2\n",
            "MoviePy - Writing audio in ./Eye Tracker Audio Converted/transcribed_speech_P5_2.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                      \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "- Converting Video To Audio for P6\n",
            "MoviePy - Writing audio in ./Eye Tracker Audio Converted/transcribed_speech_P6.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "- Converting Video To Audio for P7\n",
            "MoviePy - Writing audio in ./Eye Tracker Audio Converted/transcribed_speech_P7.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "- Converting Video To Audio for P8\n",
            "MoviePy - Writing audio in ./Eye Tracker Audio Converted/transcribed_speech_P8.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "- Converting Video To Audio for P9_1\n",
            "MoviePy - Writing audio in ./Eye Tracker Audio Converted/transcribed_speech_P9_1.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                      \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "- Converting Video To Audio for P9_2\n",
            "MoviePy - Writing audio in ./Eye Tracker Audio Converted/transcribed_speech_P9_2.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "- Converting Video To Audio for P10\n",
            "MoviePy - Writing audio in ./Eye Tracker Audio Converted/transcribed_speech_P10.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "- Converting Video To Audio for P11\n",
            "MoviePy - Writing audio in ./Eye Tracker Audio Converted/transcribed_speech_P11.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "- Converting Video To Audio for P12\n",
            "MoviePy - Writing audio in ./Eye Tracker Audio Converted/transcribed_speech_P12.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "- Converting Video To Audio for P13\n",
            "MoviePy - Writing audio in ./Eye Tracker Audio Converted/transcribed_speech_P13.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "- Converting Video To Audio for P14\n",
            "MoviePy - Writing audio in ./Eye Tracker Audio Converted/transcribed_speech_P14.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "- Converting Video To Audio for P15\n",
            "MoviePy - Writing audio in ./Eye Tracker Audio Converted/transcribed_speech_P15.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "- Converting Video To Audio for P16\n",
            "MoviePy - Writing audio in ./Eye Tracker Audio Converted/transcribed_speech_P16.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                      \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "- Converting Video To Audio for P17_1\n",
            "MoviePy - Writing audio in ./Eye Tracker Audio Converted/transcribed_speech_P17_1.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "- Converting Video To Audio for P17_2\n",
            "MoviePy - Writing audio in ./Eye Tracker Audio Converted/transcribed_speech_P17_2.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "- Converting Video To Audio for P18\n",
            "MoviePy - Writing audio in ./Eye Tracker Audio Converted/transcribed_speech_P18.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "- - Done Audio Seperation From Videos\n"
          ]
        }
      ],
      "source": [
        "import wave, math, contextlib\n",
        "import speech_recognition as sr\n",
        "from moviepy.editor import AudioFileClip\n",
        "\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "video_file_dir = './Eye Tracker Videos Raw'\n",
        "audio_file_dir = './Eye Tracker Audio Converted'\n",
        "\n",
        "allVideoFiles = [f for f in listdir(video_file_dir) if isfile(join(video_file_dir, f))]\n",
        "\n",
        "for video_file_name in allVideoFiles:\n",
        "    complete_video_file_dir = video_file_dir+'/'+video_file_name\n",
        "    audio_dir = './Eye Tracker Audios Converted'\n",
        "    part = video_file_name.split(' ')[1]\n",
        "    print('- Converting Video To Audio for',part)\n",
        "    transcribed_audio_file_name = audio_file_dir+'/'+\"transcribed_speech_\"+part+'.wav'\n",
        "    audioclip = AudioFileClip(complete_video_file_dir)\n",
        "    audioclip.write_audiofile(transcribed_audio_file_name, codec='pcm_s16le')\n",
        "    from pydub import AudioSegment\n",
        "    sound = AudioSegment.from_wav(transcribed_audio_file_name)\n",
        "    sound = sound.set_channels(1)\n",
        "    sound.export(transcribed_audio_file_name, format=\"wav\")\n",
        "\n",
        "print('- - Done Audio Seperation From Videos')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjSRrfKL9Eq3"
      },
      "source": [
        "## Converting Audios To Text Timestamps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FUeZnPi9Eq3",
        "outputId": "ec54d685-c537-401a-9fe5-4910f35b31b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "& starting ./Eye Tracker Audio Converted/transcribed_speech_P10.wav\n",
            "-- File Checked\n",
            "Converting ...\n",
            "& starting ./Eye Tracker Audio Converted/transcribed_speech_P11.wav\n",
            "-- File Checked\n",
            "Converting ...\n",
            "& starting ./Eye Tracker Audio Converted/transcribed_speech_P12.wav\n",
            "-- File Checked\n",
            "Converting ...\n",
            "& starting ./Eye Tracker Audio Converted/transcribed_speech_P13.wav\n",
            "-- File Checked\n",
            "Converting ...\n",
            "& starting ./Eye Tracker Audio Converted/transcribed_speech_P14.wav\n",
            "-- File Checked\n",
            "Converting ...\n",
            "& starting ./Eye Tracker Audio Converted/transcribed_speech_P15.wav\n",
            "-- File Checked\n",
            "Converting ...\n",
            "& starting ./Eye Tracker Audio Converted/transcribed_speech_P16.wav\n",
            "-- File Checked\n",
            "Converting ...\n",
            "& starting ./Eye Tracker Audio Converted/transcribed_speech_P17_1.wav\n",
            "-- File Checked\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function Wave_write.__del__ at 0x000001833F3F5430>\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\hwx1162214\\Anaconda3\\lib\\wave.py\", line 326, in __del__\n",
            "    self.close()\n",
            "  File \"c:\\Users\\hwx1162214\\Anaconda3\\lib\\wave.py\", line 444, in close\n",
            "    self._ensure_header_written(0)\n",
            "  File \"c:\\Users\\hwx1162214\\Anaconda3\\lib\\wave.py\", line 464, in _ensure_header_written\n",
            "    raise Error('sample width not specified')\n",
            "wave.Error: sample width not specified\n",
            "Exception ignored in: <function Wave_write.__del__ at 0x000001833F3F5430>\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\hwx1162214\\Anaconda3\\lib\\wave.py\", line 326, in __del__\n",
            "    self.close()\n",
            "  File \"c:\\Users\\hwx1162214\\Anaconda3\\lib\\wave.py\", line 444, in close\n",
            "    self._ensure_header_written(0)\n",
            "  File \"c:\\Users\\hwx1162214\\Anaconda3\\lib\\wave.py\", line 466, in _ensure_header_written\n",
            "    raise Error('sampling rate not specified')\n",
            "wave.Error: sampling rate not specified\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converting ...\n",
            "& starting ./Eye Tracker Audio Converted/transcribed_speech_P17_2.wav\n",
            "-- File Checked\n",
            "Converting ...\n",
            "& starting ./Eye Tracker Audio Converted/transcribed_speech_P18.wav\n",
            "-- File Checked\n",
            "Converting ...\n",
            "& starting ./Eye Tracker Audio Converted/transcribed_speech_P1_1.wav\n",
            "-- File Checked\n",
            "Converting ...\n",
            "& starting ./Eye Tracker Audio Converted/transcribed_speech_P1_2from.wav\n",
            "-- File Checked\n",
            "Converting ...\n",
            "& starting ./Eye Tracker Audio Converted/transcribed_speech_P2.wav\n",
            "-- File Checked\n",
            "Converting ...\n",
            "& starting ./Eye Tracker Audio Converted/transcribed_speech_P3.wav\n",
            "-- File Checked\n",
            "Converting ...\n",
            "& starting ./Eye Tracker Audio Converted/transcribed_speech_P4_1.wav\n",
            "-- File Checked\n",
            "Converting ...\n",
            "& starting ./Eye Tracker Audio Converted/transcribed_speech_P4_2.wav\n",
            "-- File Checked\n",
            "Converting ...\n",
            "& starting ./Eye Tracker Audio Converted/transcribed_speech_P5_1.wav\n",
            "-- File Checked\n",
            "Converting ...\n",
            "& starting ./Eye Tracker Audio Converted/transcribed_speech_P5_2.wav\n",
            "-- File Checked\n",
            "Converting ...\n",
            "& starting ./Eye Tracker Audio Converted/transcribed_speech_P6.wav\n",
            "-- File Checked\n",
            "Converting ...\n",
            "& starting ./Eye Tracker Audio Converted/transcribed_speech_P7.wav\n",
            "-- File Checked\n",
            "Converting ...\n",
            "& starting ./Eye Tracker Audio Converted/transcribed_speech_P8.wav\n",
            "-- File Checked\n",
            "Converting ...\n",
            "& starting ./Eye Tracker Audio Converted/transcribed_speech_P9_1.wav\n",
            "-- File Checked\n",
            "Converting ...\n",
            "& starting ./Eye Tracker Audio Converted/transcribed_speech_P9_2.wav\n",
            "-- File Checked\n",
            "Converting ...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "class custom_Word:\n",
        "    ''' A class representing a word from the JSON format for vosk speech recognition API '''\n",
        "\n",
        "    def __init__(self, dict):\n",
        "        '''\n",
        "        Parameters:\n",
        "          dict (dict) dictionary from JSON, containing:\n",
        "            conf (float): degree of confidence, from 0 to 1\n",
        "            end (float): end time of the pronouncing the word, in seconds\n",
        "            start (float): start time of the pronouncing the word, in seconds\n",
        "            word (str): recognized word\n",
        "        '''\n",
        "\n",
        "        self.conf = dict[\"conf\"]\n",
        "        self.end = dict[\"end\"]\n",
        "        self.start = dict[\"start\"]\n",
        "        self.word = dict[\"word\"]\n",
        "\n",
        "    def to_string(self):\n",
        "        ''' Returns a string describing this instance '''\n",
        "        return \"{:20} from {:.2f} sec to {:.2f} sec, confidence is {:.2f}%\".format(\n",
        "            self.word, self.start, self.end, self.conf*100)\n",
        "\n",
        "import wave\n",
        "import json\n",
        "\n",
        "from vosk import Model, KaldiRecognizer, SetLogLevel\n",
        "# import Word as custom_Word\n",
        "\n",
        "allAudioFiles = [f for f in listdir(audio_file_dir) if isfile(join(audio_file_dir, f))]\n",
        "with pd.ExcelWriter('output_audio_to_text_timestamp.xlsx') as writer:\n",
        "    for audio_filename in allAudioFiles:\n",
        "        audio_filename_ = audio_filename\n",
        "        audio_filename = audio_file_dir+'/'+audio_filename\n",
        "\n",
        "        model_path = \"models/vosk-model-en-us-0.22\"\n",
        "        print('& starting',audio_filename)\n",
        "\n",
        "        # model = Model(model_path)\n",
        "        model = Model(lang=\"en-us\")\n",
        "        # wf = wave.open(audio_filename, \"w\")\n",
        "        # wf.setsampwidth(2)\n",
        "        # wf.setnchannels(1)\n",
        "        wf = wave.open(audio_filename, 'rb')\n",
        "        if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != \"NONE\":\n",
        "            print(\"Audio file must be WAV format mono PCM.\")\n",
        "            print('n Channels: ',wf.getnchannels())\n",
        "            print('Sample Width: ', wf.getsampwidth())\n",
        "            print('Comp Type: ',wf.getcomptype())\n",
        "            # sys.exit(1)\n",
        "        else:\n",
        "            print('-- File Checked')\n",
        "        rec = KaldiRecognizer(model, wf.getframerate())\n",
        "        rec.SetWords(True)\n",
        "\n",
        "        # get the list of JSON dictionaries\n",
        "        results = []\n",
        "        # recognize speech using vosk model\n",
        "        while True:\n",
        "            data = wf.readframes(4000)\n",
        "            if len(data) == 0:\n",
        "                break\n",
        "            if rec.AcceptWaveform(data):\n",
        "                part_result = json.loads(rec.Result())\n",
        "                results.append(part_result)\n",
        "        part_result = json.loads(rec.FinalResult())\n",
        "        results.append(part_result)\n",
        "\n",
        "        # convert list of JSON dictionaries to list of 'Word' objects\n",
        "        print('Converting ...')\n",
        "        list_of_Words = []\n",
        "        for sentence in results:\n",
        "            if len(sentence) == 1:\n",
        "                # sometimes there are bugs in recognition\n",
        "                # and it returns an empty dictionary\n",
        "                # {'text': ''}\n",
        "                continue\n",
        "            for obj in sentence['result']:\n",
        "                w = custom_Word(obj)  # create custom Word object\n",
        "                list_of_Words.append(w)  # and add it to list\n",
        "\n",
        "        wf.close()  # close audiofile\n",
        "\n",
        "        # output to the screen\n",
        "        conf = []\n",
        "        end = []\n",
        "        start = []\n",
        "        wd = []\n",
        "        for word in list_of_Words:\n",
        "            # print(word.to_string())\n",
        "            conf.append(word.conf)\n",
        "            end.append(word.end)\n",
        "            start.append(word.start)\n",
        "            wd.append(word.word)\n",
        "        pd.DataFrame({'confidence':conf, 'end':end, 'start':start, 'word':wd}).to_excel(writer, sheet_name=audio_filename_)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "2b1b3311c7f13d0f4a69b22499e392e467d9099308f8a658144b7ae729cac498"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}