{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PeFmnavkFDBU"
      },
      "source": [
        "#### Import packages for setting up the essential tools and libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJLGPvokcpur"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, SGDClassifier, LogisticRegression\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, roc_auc_score, precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module=\"my_module\")\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FNIOTLxNAHiy"
      },
      "source": [
        "#### Read data and data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VjF08wFdKUM"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('your_data.csv')# If you need data, please email haoyan.jiang@mail.utoronto.ca for data\n",
        "replacement_dict = {'Saccade': 0, 'Fixation': 1, 'Unclassified': 2, 'EyesNotFound': 3}\n",
        "\n",
        "# Replace the values in the column\n",
        "df['Eye movement type'] = df['Eye movement type'].replace(replacement_dict)\n",
        "\n",
        "feature_names = ['Gaze event duration', 'Fixation point X',\n",
        "       'Fixation point Y', 'Eye movement type', 'Accelerometer X',\n",
        "       'Accelerometer Y', 'Accelerometer Z', 'Gyro X', 'Gyro Y', 'Gyro Z',\n",
        "       'Gaze point X', 'Gaze point Y', 'Gaze point 3D X', 'Gaze point 3D Y',\n",
        "       'Gaze point 3D Z', 'Gaze direction left X', 'Gaze direction left Y',\n",
        "       'Gaze direction left Z', 'Gaze direction right X',\n",
        "       'Gaze direction right Y', 'Gaze direction right Z',\n",
        "       'Pupil position left X', 'Pupil position left Y',\n",
        "       'Pupil position left Z', 'Pupil position right X',\n",
        "       'Pupil position right Y', 'Pupil position right Z',\n",
        "       'Pupil diameter left', 'Pupil diameter right']\n",
        "X = df[feature_names]\n",
        "imputer = SimpleImputer()\n",
        "X_filled = imputer.fit_transform(X)\n",
        "X_filled = pd.DataFrame(X_filled, columns=feature_names)\n",
        "X_filled['Time Window'] = df['Time Window']\n",
        "X_filled['is_distraction'] = df['is_distraction']\n",
        "X_filled['videoNum'] = df['videoNum']\n",
        "X_filled['Participant ID'] = df['Participant ID']\n",
        "X_filled['order'] = df['order']\n",
        "X_filled['interest_level'] = df['interest_level']\n",
        "\n",
        "\n",
        "X_filled = X_filled[X_filled['Time Window'].notna()]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lA8OK-yPtcbU"
      },
      "source": [
        "Parsing and Extracting data windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0B45ZErdNIE"
      },
      "outputs": [],
      "source": [
        "def parse_data(df, window_size, include = True):\n",
        "### THE function for data window parsing\n",
        "### return 1) parsed window contains EITHER distraction or attention\n",
        "### return 2) parsed window contains neigher distraction nor attention, and not overlap with 1)\n",
        "\n",
        "\n",
        "  all_windows = [] # windows for verbolization\n",
        "  all_windows_neg = []\n",
        "  tracked = False\n",
        "  last_time = None\n",
        "  last_index = -1\n",
        "  videoN = -1\n",
        "  for index, row in df.iloc[::-1].iterrows():\n",
        "    if tracked ==True:\n",
        "      # print('Here')\n",
        "      if row['is_distraction']!='None' or row['videoNum']!=videoN:\n",
        "        res = row['Time Window'].strip('][').split(', ')\n",
        "        # print(last_time, float(res[0]))\n",
        "        if ((last_time - float(res[0])) <= window_size):\n",
        "          if include and (last_index-index>3):\n",
        "            all_windows.append(df.iloc[index+1:last_index+2].copy())\n",
        "        last_time = float(res[1])\n",
        "        last_index = index\n",
        "        if row['videoNum']!=videoN and row['is_distraction']=='None':\n",
        "          tracked=False\n",
        "          # print(1, last_time-float(res[0]))\n",
        "          # print('find a window')\n",
        "        videoN = row['videoNum']\n",
        "      elif row['is_distraction']=='None':\n",
        "        res = row['Time Window'].strip('][').split(', ')\n",
        "        if row['videoNum']!=videoN:\n",
        "          tracked = False\n",
        "          last_index = index\n",
        "          videoN = row['videoNum']\n",
        "        if (last_time - float(res[0])) > window_size:\n",
        "          all_windows.append(df.iloc[index+1:last_index+1].copy())\n",
        "          tracked = False\n",
        "          last_index = index\n",
        "          videoN = row['videoNum']\n",
        "          # print(2, last_time-float(res[0]))\n",
        "\n",
        "          # print('find a window')\n",
        "    else:\n",
        "      if row['is_distraction']!='None':\n",
        "        # print('window')\n",
        "        res = row['Time Window'].strip('][').split(', ')\n",
        "        tracked = True\n",
        "        last_time = float(res[1])\n",
        "        all_windows_neg.append(df.iloc[index+1:last_index])\n",
        "        last_index = index\n",
        "        videoN = row['videoNum']\n",
        "\n",
        "  ## negation of window data\n",
        "  finite_all_windows_neg = []\n",
        "  for wind in all_windows_neg:\n",
        "    if wind.shape[0]>0:\n",
        "      start_time = float(wind.iloc[0]['Time Window'].strip('][').split(', ')[0])\n",
        "      for index, row in wind.iterrows():\n",
        "        t = float(row['Time Window'].strip('][').split(', ')[1])\n",
        "        if (t-start_time)>=window_size:\n",
        "          finite_all_windows_neg.append(wind.loc[0:index-1].copy())\n",
        "          break\n",
        "  print(len(all_windows), len(finite_all_windows_neg))\n",
        "  return all_windows, finite_all_windows_neg"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mmbTqwZqd2tX"
      },
      "source": [
        "#### Feature Engineering and Aggregation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NW-hNHcd0eQ"
      },
      "outputs": [],
      "source": [
        "#std\n",
        "def get_std_df(df_list, column_names):\n",
        "    std_list = []\n",
        "\n",
        "    for df in df_list:\n",
        "        std_row = []\n",
        "        for col in column_names:\n",
        "            std_row.append(np.std(df[col]))\n",
        "        std_list.append(std_row)\n",
        "\n",
        "    std_df = pd.DataFrame(std_list, columns=column_names)\n",
        "\n",
        "    return std_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98TSiI8Gd5r1"
      },
      "outputs": [],
      "source": [
        "#sum\n",
        "def calculate_avg_a(df_list, column_names):\n",
        "    l1 = []\n",
        "    for df in df_list:\n",
        "        df = df.reset_index(drop=True)\n",
        "        a_list = []\n",
        "        for i in range(len(df[column_names[0]])):\n",
        "            if i > 0:\n",
        "                a = np.sqrt(np.square(df[column_names[0]][i] - df[column_names[0]][i-1]) \\\n",
        "                + np.square(df[column_names[1]][i] - df[column_names[1]][i-1]) \\\n",
        "                + np.square(df[column_names[2]][i] - df[column_names[2]][i-1]))\n",
        "                a_list.append(a)\n",
        "        sum_a = np.sum(a_list)\n",
        "        l1.append(sum_a)\n",
        "    return pd.DataFrame({'avg_a': l1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25r9sskzd8K_"
      },
      "outputs": [],
      "source": [
        "def Saccade_fixation_ratio(df_list):\n",
        "    fixation_count = []\n",
        "    saccade_count = []\n",
        "\n",
        "    for df in df_list:\n",
        "\n",
        "        fixation = df[df['Eye movement type'] == 0]['Eye movement type'].count()\n",
        "        saccade = df[df['Eye movement type'] == 1]['Eye movement type'].count()\n",
        "\n",
        "        fixation_count.append(fixation/len(df))\n",
        "        saccade_count.append(saccade/len(df))\n",
        "\n",
        "    result = pd.DataFrame({'Fixation count': fixation_count, 'Saccade count': saccade_count})\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pueuaSTd-P4"
      },
      "outputs": [],
      "source": [
        "def absolute_changes(df_list, col_name):\n",
        "  max = 0\n",
        "  min = 0\n",
        "  a = 0\n",
        "  change = []\n",
        "  for df in df_list:\n",
        "    for i in df[col_name]:\n",
        "      if i < min:\n",
        "        min = i\n",
        "      elif i > max:\n",
        "        max = i\n",
        "    a = abs(max - min)\n",
        "    min = 0\n",
        "    max = 0\n",
        "    change.append(a)\n",
        "\n",
        "  return pd.DataFrame({'abs_change': change})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjhS2q2QeA8-"
      },
      "outputs": [],
      "source": [
        "def avg_col(df_list, col_name):\n",
        "  y = []\n",
        "  avg = []\n",
        "  for df in df_list:\n",
        "    for i in df[col_name]:\n",
        "      y.append(i)\n",
        "    average = abs(np.mean(y))\n",
        "    y = []\n",
        "    avg.append(average)\n",
        "  return pd.DataFrame({'avg1': avg})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXSaLwZEEAmo"
      },
      "outputs": [],
      "source": [
        "def con_df(df1, df2, df3):\n",
        "  #concatenated = df1.join(df2)\n",
        "  concatenated = df1.join([df2, df3])\n",
        "  return concatenated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUgtsAK7eOiK"
      },
      "outputs": [],
      "source": [
        "def longest_fixation(df_list):\n",
        "    fixation_durations = []  # List to store the longest fixation durations\n",
        "\n",
        "    for idx, df in enumerate(df_list, start=1):\n",
        "        fixation_range_container = []\n",
        "        start_time = 0\n",
        "\n",
        "        for index, row in df.iterrows():\n",
        "            eye_movement_type = row['Eye movement type']\n",
        "            time_window = row['Time Window']\n",
        "\n",
        "            if eye_movement_type == 1 and not row.equals(df.iloc[-1]):\n",
        "                time_range = [float(t) for t in time_window.strip('][').split(', ')]\n",
        "                last_time = time_range[1]\n",
        "                first_time = time_range[0]\n",
        "\n",
        "                if start_time == 0:\n",
        "                    start_time = first_time\n",
        "\n",
        "            if eye_movement_type != 1 and not row.equals(df.iloc[-1]):\n",
        "                time_range = [float(t) for t in time_window.strip('][').split(', ')]\n",
        "                first_time_2 = time_range[0]\n",
        "\n",
        "                if start_time != 0:\n",
        "                    fixation_range_container.append(first_time_2 - start_time)\n",
        "                    start_time = 0\n",
        "\n",
        "            if row.equals(df.iloc[-1]):\n",
        "                if eye_movement_type == 1:\n",
        "                    time_range = [float(t) for t in time_window.strip('][').split(', ')]\n",
        "                    last_time = time_range[1]\n",
        "                    first_time = time_range[0]\n",
        "\n",
        "                    if start_time == 0:\n",
        "                        fixation_range_container.append(last_time - first_time)\n",
        "                        start_time = 0\n",
        "                        fixation_durations.append(max(fixation_range_container))\n",
        "                    else:\n",
        "                        fixation_range_container.append(last_time - start_time)\n",
        "                        fixation_durations.append(max(fixation_range_container))\n",
        "                        start_time = 0\n",
        "\n",
        "    # Create a DataFrame with fixation durations\n",
        "    lg_df = pd.DataFrame({'Longest Fixation Duration': fixation_durations})\n",
        "\n",
        "    return lg_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jf3elfg3eXF4"
      },
      "outputs": [],
      "source": [
        "def verbalization_lag(df_list):\n",
        "    lag_durations = []  # List to store verbalization lag durations\n",
        "\n",
        "    for idx, df in enumerate(df_list, start=1):\n",
        "        last_index_label = df.index.max()\n",
        "        last_row = df.loc[last_index_label]\n",
        "        start_time = 0\n",
        "        end_list = []\n",
        "        fixation_range_container = []\n",
        "\n",
        "        for index, row in df.iterrows():\n",
        "            eye_movement_type = row['Eye movement type']\n",
        "            time_window = row['Time Window']\n",
        "\n",
        "            if eye_movement_type == 1 and not row.equals(last_row):\n",
        "                time_range = [float(t) for t in time_window.strip('][').split(', ')]\n",
        "                last_time = time_range[1]\n",
        "                first_time = time_range[0]\n",
        "\n",
        "                if start_time == 0:\n",
        "                    start_time = first_time\n",
        "\n",
        "            if eye_movement_type != 1 and not row.equals(last_row):\n",
        "                time_range = [float(t) for t in time_window.strip('][').split(', ')]\n",
        "                first_time_2 = time_range[0]\n",
        "\n",
        "                if start_time != 0:\n",
        "                    fixation_range_container.append(first_time_2 - start_time)\n",
        "                    start_time = 0\n",
        "                    end_list.append(first_time_2)\n",
        "\n",
        "            if row.equals(last_row):\n",
        "                if eye_movement_type == 1:\n",
        "                    time_range = [float(t) for t in time_window.strip('][').split(', ')]\n",
        "                    last_time = time_range[1]\n",
        "                    first_time = time_range[0]\n",
        "\n",
        "                    if start_time == 0:\n",
        "                        fixation_range_container.append(last_time - first_time)\n",
        "                        end_list.append(last_time)\n",
        "                        start_time = 0\n",
        "                        lag_durations.append(max(fixation_range_container))\n",
        "                    else:\n",
        "                        fixation_range_container.append(last_time - start_time)\n",
        "                        end_list.append(last_time)\n",
        "                        lag_durations.append(max(fixation_range_container))\n",
        "                else:\n",
        "                    if start_time != 0:\n",
        "                        time_range = [float(t) for t in time_window.strip('][').split(', ')]\n",
        "                        first_time_2 = time_range[0]\n",
        "                        fixation_range_container.append(first_time_2 - start_time)\n",
        "                        end_list.append(first_time_2)\n",
        "                        start_time = 0\n",
        "                        lag_durations.append(max(fixation_range_container))\n",
        "                    elif len(fixation_range_container) == 0:\n",
        "                        lag_durations.append(0)\n",
        "                    elif len(fixation_range_container) != 0 and start_time == 0:\n",
        "                        lag_durations.append(max(fixation_range_container))\n",
        "\n",
        "        max_fixation_index = fixation_range_container.index(max(fixation_range_container))\n",
        "        last_time_range = [float(t) for t in last_row['Time Window'].strip('][').split(', ')]\n",
        "        start_point = last_time_range[0]\n",
        "\n",
        "        if start_point - end_list[max_fixation_index] < 0:\n",
        "            lag_durations.append(start_point - end_list[max_fixation_index] + max(fixation_range_container))\n",
        "        else:\n",
        "            lag_durations.append(start_point - end_list[max_fixation_index] + max(fixation_range_container))\n",
        "\n",
        "    lag_df = pd.DataFrame({'Verbalization Lag Duration': lag_durations})\n",
        "\n",
        "    return lag_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_Xh5xrRDOaj"
      },
      "outputs": [],
      "source": [
        "def Temporal_movement(df_list, col_names):\n",
        "    fixation_to_saccade_ratio = Saccade_fixation_ratio(df_list).reset_index(drop=True)\n",
        "    avg_a = calculate_avg_a(df_list, col_names).reset_index(drop=True)\n",
        "    longest_fixation_range = longest_fixation(df_list)\n",
        "    verbalization_lag = verbalization_lag(df_list)\n",
        "    result = pd.concat([fixation_to_saccade_ratio, avg_a, longest_fixation_range, verbalization_lag], axis=1, ignore_index=True)\n",
        "    result.columns = ['Fixation-to-Saccade Ratio', 'Average \"a\"', 'Longest Fixation Range', 'Verbalization Lag']\n",
        "    return result\n",
        "\n",
        "\n",
        "\n",
        "def Gaze_pupil(df_list, col_names_1):\n",
        "    # Calculate standard deviations and reset index\n",
        "    std_fixation_x_y = get_std_df(df_list, ['Fixation point X', 'Fixation point Y']).reset_index(drop=True)\n",
        "    std_gaze_3d = get_std_df(df_list, col_names_1).reset_index(drop=True)\n",
        "    std_gaze_point = get_std_df(df_list, ['Gaze point X', 'Gaze point Y']).reset_index(drop=True)\n",
        "    std_gaze_dir_left = get_std_df(df_list, ['Gaze direction left X', 'Gaze direction left Y', 'Gaze direction left Z']).reset_index(drop=True)\n",
        "    std_gaze_dir_right = get_std_df(df_list, ['Gaze direction right X', 'Gaze direction right Y', 'Gaze direction right Z']).reset_index(drop=True)\n",
        "    std_pupil_pos_left = get_std_df(df_list, ['Pupil position left X', 'Pupil position left Y', 'Pupil position left Z']).reset_index(drop=True)\n",
        "    std_pupil_pos_right = get_std_df(df_list, ['Pupil position right X', 'Pupil position right Y', 'Pupil position right Z']).reset_index(drop=True)\n",
        "    std_pupil_diameter = get_std_df(df_list, ['Pupil diameter left', 'Pupil diameter right']).reset_index(drop=True)\n",
        "\n",
        "    # Calculate averages and reset index\n",
        "    avg_fixation_x = avg_col(df_list, 'Fixation point X').reset_index(drop=True)\n",
        "    avg_fixation_y = avg_col(df_list, 'Fixation point Y').reset_index(drop=True)\n",
        "    avg_gaze_3d_x = avg_col(df_list, 'Gaze point 3D X').reset_index(drop=True)\n",
        "    avg_gaze_3d_y = avg_col(df_list, 'Gaze point 3D Y').reset_index(drop=True)\n",
        "    avg_gaze_3d_z = avg_col(df_list, 'Gaze point 3D Z').reset_index(drop=True)\n",
        "    avg_gaze_point_x = avg_col(df_list, 'Gaze point X').reset_index(drop=True)\n",
        "    avg_gaze_point_y = avg_col(df_list, 'Gaze point Y').reset_index(drop=True)\n",
        "    avg_gaze_dir_left_x = avg_col(df_list, 'Gaze direction left X').reset_index(drop=True)\n",
        "    avg_gaze_dir_left_y = avg_col(df_list, 'Gaze direction left Y').reset_index(drop=True)\n",
        "    avg_gaze_dir_left_z = avg_col(df_list, 'Gaze direction left Z').reset_index(drop=True)\n",
        "    avg_gaze_dir_right_x = avg_col(df_list, 'Gaze direction right X').reset_index(drop=True)\n",
        "    avg_gaze_dir_right_y = avg_col(df_list, 'Gaze direction right Y').reset_index(drop=True)\n",
        "    avg_gaze_dir_right_z = avg_col(df_list, 'Gaze direction right Z').reset_index(drop=True)\n",
        "    avg_pupil_pos_left_x = avg_col(df_list, 'Pupil position left X').reset_index(drop=True)\n",
        "    avg_pupil_pos_left_y = avg_col(df_list, 'Pupil position left Y').reset_index(drop=True)\n",
        "    avg_pupil_pos_left_z = avg_col(df_list, 'Pupil position left Z').reset_index(drop=True)\n",
        "    avg_pupil_pos_right_x = avg_col(df_list, 'Pupil position right X').reset_index(drop=True)\n",
        "    avg_pupil_pos_right_y = avg_col(df_list, 'Pupil position right Y').reset_index(drop=True)\n",
        "    avg_pupil_pos_right_z = avg_col(df_list, 'Pupil position right Z').reset_index(drop=True)\n",
        "    avg_pupil_diameter_left = avg_col(df_list, 'Pupil diameter left')\n",
        "    avg_pupil_diameter_right = avg_col(df_list, 'Pupil diameter right')\n",
        "\n",
        "    # Calculate absolute changes and reset index\n",
        "    abs_change_gaze_3d_x = absolute_changes(df_list, 'Gaze point 3D X').reset_index(drop=True)\n",
        "    abs_change_gaze_3d_y = absolute_changes(df_list, 'Gaze point 3D Y').reset_index(drop=True)\n",
        "    abs_change_gaze_3d_z = absolute_changes(df_list, 'Gaze point 3D Z').reset_index(drop=True)\n",
        "\n",
        "    # Concatenate all dataframes\n",
        "    result = pd.concat([\n",
        "        std_fixation_x_y, avg_fixation_x, avg_fixation_y,\n",
        "        std_gaze_3d, abs_change_gaze_3d_x, abs_change_gaze_3d_y, abs_change_gaze_3d_z,\n",
        "        avg_gaze_3d_x, avg_gaze_3d_y, avg_gaze_3d_z,\n",
        "        std_gaze_point, avg_gaze_point_x, avg_gaze_point_y,\n",
        "        std_gaze_dir_left, avg_gaze_dir_left_x, avg_gaze_dir_left_y, avg_gaze_dir_left_z,\n",
        "        std_gaze_dir_right, avg_gaze_dir_right_x, avg_gaze_dir_right_y, avg_gaze_dir_right_z,\n",
        "        std_pupil_pos_left, avg_pupil_pos_left_x, avg_pupil_pos_left_y, avg_pupil_pos_left_z,\n",
        "        std_pupil_pos_right, avg_pupil_pos_right_x, avg_pupil_pos_right_y, avg_pupil_pos_right_z,\n",
        "        std_pupil_diameter, avg_pupil_diameter_left, avg_pupil_diameter_right], axis=1, ignore_index=True)\n",
        "\n",
        "    # Define meaningful column names\n",
        "    new_name = ['SD of Fixation point X', 'SD of Fixation point Y',\n",
        "                'Avg of Fixation point X', 'Avg of Fixation point Y',\n",
        "                'SD of Gaze point 3D X', 'SD of Gaze point 3D Y', 'SD of Gaze point 3D Z',\n",
        "                'Abs change of Gaze point 3D X', 'Abs change of Gaze point 3D Y', 'Abs change of Gaze point 3D Z',\n",
        "                'Avg of Gaze point 3D X', 'Avg of Gaze point 3D Y', 'Avg of Gaze point 3D Z',\n",
        "                'SD of Gaze point X', 'SD of Gaze point Y', 'Avg of Gaze point X', 'Avg of Gaze point Y',\n",
        "                'SD of Gaze direction left X', 'SD of Gaze direction left Y', 'SD of Gaze direction left Z',\n",
        "                'Avg of Gaze direction left X', 'Avg of Gaze direction left Y', 'Avg of Gaze direction left Z',\n",
        "                'SD of Gaze direction right X', 'SD of Gaze direction right Y', 'SD of Gaze direction right Z',\n",
        "                'Avg of Gaze direction right X', 'Avg of Gaze direction right Y', 'Avg of Gaze direction right Z',\n",
        "                'SD of Pupil position left X', 'SD of Pupil position left Y', 'SD of Pupil position left Z',\n",
        "                'Avg of Pupil position left X', 'Avg of Pupil position left Y', 'Avg of Pupil position left Z',\n",
        "                'SD of Pupil position right X', 'SD of Pupil position right Y', 'SD of Pupil position right Z',\n",
        "                'Avg of Pupil position right X', 'Avg of Pupil position right Y', 'Avg of Pupil position right Z',\n",
        "                'SD of Pupil diameter left', 'SD of Pupil diameter right',\n",
        "                'Avg of Pupil diameter left', 'Avg of Pupil diameter right']\n",
        "\n",
        "    # Assign column names to the result dataframe\n",
        "    result.columns = new_name\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def headmovement_orientation(df_list, col_names):\n",
        "    # Calculate absolute changes and reset index\n",
        "    abs_gyro_x = absolute_changes(df_list, 'Gyro X').reset_index(drop=True)\n",
        "    abs_gyro_y = absolute_changes(df_list, 'Gyro Y').reset_index(drop=True)\n",
        "    abs_gyro_z = absolute_changes(df_list, 'Gyro Z').reset_index(drop=True)\n",
        "\n",
        "    # Calculate averages and reset index\n",
        "    avg_gyro_x = avg_col(df_list, 'Gyro X').reset_index(drop=True)\n",
        "    avg_gyro_y = avg_col(df_list, 'Gyro Y').reset_index(drop=True)\n",
        "    avg_gyro_z = avg_col(df_list, 'Gyro Z').reset_index(drop=True)\n",
        "\n",
        "    # Calculate standard deviations and reset index\n",
        "    std_col_names = get_std_df(df_list, col_names).reset_index(drop=True)\n",
        "    std_accelerometer_xyz = get_std_df(df_list, ['Accelerometer X', 'Accelerometer Y', 'Accelerometer Z']).reset_index(drop=True)\n",
        "\n",
        "    # Calculate average 'a' (not sure what 'a' represents) and reset index\n",
        "    avg_a = calculate_avg_a(df_list, col_names).reset_index(drop=True)\n",
        "    avg_accelerometer_x = avg_col(df_list, 'Accelerometer X').reset_index(drop=True)\n",
        "    avg_accelerometer_y = avg_col(df_list, 'Accelerometer Y').reset_index(drop=True)\n",
        "    avg_accelerometer_z = avg_col(df_list, 'Accelerometer Z').reset_index(drop=True)\n",
        "    avg_trajectory_length_accelerometer = calculate_avg_a(df_list, ['Accelerometer X', 'Accelerometer Y', 'Accelerometer Z']).reset_index(drop=True)\n",
        "\n",
        "    # Concatenate all dataframes\n",
        "    result = pd.concat([\n",
        "        abs_gyro_x, abs_gyro_y, abs_gyro_z,\n",
        "        avg_gyro_x, avg_gyro_y, avg_gyro_z,\n",
        "        std_col_names, avg_a,\n",
        "        std_accelerometer_xyz, avg_accelerometer_x, avg_accelerometer_y, avg_accelerometer_z,\n",
        "        avg_trajectory_length_accelerometer\n",
        "    ], axis=1, ignore_index=True)\n",
        "\n",
        "    # Define meaningful column names\n",
        "    new_name = ['Abs_Gyro_X', 'Abs_Gyro_Y', 'Abs_Gyro_Z',\n",
        "                'Avg_Gyro_X', 'Avg_Gyro_Y', 'Avg_Gyro_Z',\n",
        "                'SD_Gyro_X', 'SD_Gyro_Y', 'SD_Gyro_Z', 'Trajectory_Length_Gyro',\n",
        "                'SD_Accelerometer_X', 'SD_Accelerometer_Y', 'SD_Accelerometer_Z',\n",
        "                'Avg_Accelerometer_X', 'Avg_Accelerometer_Y', 'Avg_Accelerometer_Z', 'Trajectory_Length_Accelerometer']\n",
        "\n",
        "    # Assign column names to the result dataframe\n",
        "    result.columns = new_name\n",
        "\n",
        "    return result\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "POmZ2bLJuIVx"
      },
      "source": [
        "#### Remove useless windows(windows without saccade and fixation) automatically"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6K1J1Mlecpg"
      },
      "outputs": [],
      "source": [
        "def remove_useless_window(window_list, neg_window_list):\n",
        "    useless_window_indexes = []\n",
        "    useless_neg_window_indexes = []\n",
        "\n",
        "    longest_fixation_window = find_longest_fixation(window_list)\n",
        "    longest_fixation_neg_window = find_longest_fixation(neg_window_list)\n",
        "\n",
        "    for i in range(len(longest_fixation_window['ColumnA'])):\n",
        "        if longest_fixation_window['ColumnA'][i] == 0:\n",
        "            useless_window_indexes.append(i)\n",
        "\n",
        "    for i in range(len(longest_fixation_neg_window['ColumnA'])):\n",
        "        if longest_fixation_neg_window['ColumnA'][i] == 0:\n",
        "            useless_neg_window_indexes.append(i)\n",
        "\n",
        "    useful_windows = [window for i, window in enumerate(window_list) if i not in useless_window_indexes]\n",
        "    useful_neg_windows = [window for i, window in enumerate(neg_window_list) if i not in useless_neg_window_indexes]\n",
        "\n",
        "    return useful_windows, useful_neg_windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lcyLrJzPYWi",
        "outputId": "79e86593-09f4-418b-f2d5-0daa072359f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2806 2515\n",
            "2397 1456\n",
            "1809 881\n",
            "1328 597\n",
            "978 432\n",
            "2865 2923\n"
          ]
        }
      ],
      "source": [
        "window_1s, neg_window_1s = parse_data(X_filled, 1, include=False)\n",
        "window_2s, neg_window_2s = parse_data(X_filled, 2, include=False)\n",
        "window_3s, neg_window_3s = parse_data(X_filled, 3, include=False)\n",
        "window_4s, neg_window_4s = parse_data(X_filled, 4, include=False)\n",
        "window_5s, neg_window_5s = parse_data(X_filled, 5, include=False)\n",
        "window_0_5s, neg_window_0_5s = parse_data(X_filled, 0.5, include=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLSvnyq8pwkk"
      },
      "outputs": [],
      "source": [
        "# remove some useless windows(does not contain any saccade and fixation) manually\n",
        "del neg_window_0_5s[2810:2833]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXJikaZGpyvp"
      },
      "outputs": [],
      "source": [
        "new_window_1s, new_neg_window_1s = remove_useless_window(window_1s, neg_window_1s)\n",
        "new_window_2s, new_neg_window_2s = remove_useless_window(window_2s, neg_window_2s)\n",
        "new_window_3s, new_neg_window_3s = remove_useless_window(window_3s, neg_window_3s)\n",
        "new_window_4s, new_neg_window_4s = remove_useless_window(window_4s, neg_window_4s)\n",
        "new_window_5s, new_neg_window_5s = remove_useless_window(window_5s, neg_window_5s)\n",
        "new_window_0_5s, new_neg_window_0_5s = remove_useless_window(window_0_5s, neg_window_0_5s)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dRrJHEzLsgbJ"
      },
      "source": [
        "#### Define response variable"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "28_sO-C7sYP5"
      },
      "source": [
        "Think-aloud(based on 'interest_level' column)\n",
        "\n",
        "when interest_level == nan : 0\n",
        "\n",
        "when interest_level == 0 : 1\n",
        "\n",
        "when interest_level >= 1 : 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIK0d_uJp02L"
      },
      "outputs": [],
      "source": [
        "def response_cta(df_list1, df_list2):\n",
        "  a = []\n",
        "  for df in df_list1:\n",
        "    for i in df['interest_level']:\n",
        "      if i == 0:\n",
        "        a.append(1)\n",
        "      elif i >= 1:\n",
        "        a.append(2)\n",
        "  df2 = pd.DataFrame(a, columns=['Response'])\n",
        "  length2 = len(df_list2)\n",
        "  df3 = pd.DataFrame(0, index=range(length2), columns=['Response'])\n",
        "  df_concat = pd.concat([df2, df3])\n",
        "  df_concat = df_concat.reset_index(drop=True)\n",
        "  return df_concat"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TYVWDGlvsR5t"
      },
      "source": [
        "Distraction(based on 'is_distraction' column)\n",
        "\n",
        "\n",
        "When is_distraction == NaN : 0\n",
        "\n",
        "when is_distraction == True : 1\n",
        "\n",
        "when is_distraction == False : 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqjBMfjRsNuo"
      },
      "outputs": [],
      "source": [
        "def response_dis(df_list1, df_list2):\n",
        "  a = []\n",
        "  for df in df_list1:\n",
        "    for i in df['is_distraction']:\n",
        "      if i == 'False':\n",
        "        a.append(2)\n",
        "      elif i == 'True':\n",
        "        a.append(1)\n",
        "  df2 = pd.DataFrame(a, columns=['Response'])\n",
        "  length2 = len(df_list2)\n",
        "  df3 = pd.DataFrame(0, index=range(length2), columns=['Response'])\n",
        "  df_concat = pd.concat([df2, df3])\n",
        "  df_concat = df_concat.reset_index(drop=True)\n",
        "  return df_concat"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AJg0QV8AEwgn"
      },
      "source": [
        "### Derive X & y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQe6KWrpEUyJ"
      },
      "outputs": [],
      "source": [
        "def get_x_y_c(df1, df2):\n",
        "    # Calculate temporal features for the first dataset\n",
        "    temporal_features1 = Temporal_movement(df1, ['Gaze point 3D X', 'Gaze point 3D Y', 'Gaze point 3D Z'])\n",
        "\n",
        "    # Calculate temporal features for the second dataset\n",
        "    temporal_features2 = Temporal_movement(df2, ['Gaze point 3D X', 'Gaze point 3D Y', 'Gaze point 3D Z'])\n",
        "\n",
        "    # Calculate gaze and pupil features for the first dataset\n",
        "    gaze_pupil_features1 = Gaze_pupil(df1, ['Gaze point 3D X', 'Gaze point 3D Y', 'Gaze point 3D Z'])\n",
        "\n",
        "    # Calculate gaze and pupil features for the second dataset\n",
        "    gaze_pupil_features2 = Gaze_pupil(df2, ['Gaze point 3D X', 'Gaze point 3D Y', 'Gaze point 3D Z'])\n",
        "\n",
        "    # Calculate head movement orientation features for the first dataset\n",
        "    head_movement_features1 = headmovement_orientation(df1, ['Gyro X', 'Gyro Y', 'Gyro Z'])\n",
        "\n",
        "    # Calculate head movement orientation features for the second dataset\n",
        "    head_movement_features2 = headmovement_orientation(df2, ['Gyro X', 'Gyro Y', 'Gyro Z'])\n",
        "\n",
        "    # Combine features for the first dataset\n",
        "    X1 = con_df(temporal_features1, gaze_pupil_features1, head_movement_features1)\n",
        "\n",
        "    # Combine features for the second dataset\n",
        "    X2 = con_df(temporal_features2, gaze_pupil_features2, head_movement_features2)\n",
        "\n",
        "    # Concatenate both datasets\n",
        "    X = pd.concat([X1, X2])\n",
        "    X = X.reset_index(drop=True)\n",
        "\n",
        "    # Calculate the response variable\n",
        "    y = response_cta(df1, df2)\n",
        "\n",
        "    return X, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0AsDEF6Eg8D"
      },
      "outputs": [],
      "source": [
        "def get_x_y_d(df1, df2):\n",
        "    # Calculate temporal features for the first dataset\n",
        "    temporal_features1 = Temporal_movement(df1, ['Gaze point 3D X', 'Gaze point 3D Y', 'Gaze point 3D Z'])\n",
        "\n",
        "    # Calculate temporal features for the second dataset\n",
        "    temporal_features2 = Temporal_movement(df2, ['Gaze point 3D X', 'Gaze point 3D Y', 'Gaze point 3D Z'])\n",
        "\n",
        "    # Calculate gaze and pupil features for the first dataset\n",
        "    gaze_pupil_features1 = Gaze_pupil(df1, ['Gaze point 3D X', 'Gaze point 3D Y', 'Gaze point 3D Z'])\n",
        "\n",
        "    # Calculate gaze and pupil features for the second dataset\n",
        "    gaze_pupil_features2 = Gaze_pupil(df2, ['Gaze point 3D X', 'Gaze point 3D Y', 'Gaze point 3D Z'])\n",
        "\n",
        "    # Calculate head movement orientation features for the first dataset\n",
        "    head_movement_features1 = headmovement_orientation(df1, ['Gyro X', 'Gyro Y', 'Gyro Z'])\n",
        "\n",
        "    # Calculate head movement orientation features for the second dataset\n",
        "    head_movement_features2 = headmovement_orientation(df2, ['Gyro X', 'Gyro Y', 'Gyro Z'])\n",
        "\n",
        "    # Combine features for the first dataset\n",
        "    X1 = con_df(temporal_features1, gaze_pupil_features1, head_movement_features1)\n",
        "\n",
        "    # Combine features for the second dataset\n",
        "    X2 = con_df(temporal_features2, gaze_pupil_features2, head_movement_features2)\n",
        "\n",
        "    # Concatenate both datasets\n",
        "    X = pd.concat([X1, X2])\n",
        "    X = X.reset_index(drop=True)\n",
        "\n",
        "    # Calculate the response variable\n",
        "    y = response_dis(df1, df2)\n",
        "\n",
        "    return X, y\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_1ZhTa_SsKJO"
      },
      "source": [
        "##### X, y for think-aloud with different window size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouu-SosVEX80"
      },
      "outputs": [],
      "source": [
        "#X_0_2s, y_0_2s = get_x_y(window_0_2s, neg_window_0_2s)\n",
        "X_0_5s_c, y_0_5s_c = get_x_y_c(new_window_0_5s, new_neg_window_0_5s)\n",
        "X_1s_c, y_1s_c = get_x_y_c(new_window_1s, new_neg_window_1s)\n",
        "#X_1_5s, y_1_5s = get_x_y(window_1_5s, neg_window_1_5s)\n",
        "X_2s_c, y_2s_c = get_x_y_c(new_window_2s, new_neg_window_2s)\n",
        "#X_2_5s, y_2_5s = get_x_y(window_2_5s, neg_window_2_5s)\n",
        "X_3s_c, y_3s_c = get_x_y_c(new_window_3s, new_neg_window_3s)\n",
        "#X_3_5s, y_3_5s = get_x_y(window_3_5s, neg_window_3_5s)\n",
        "X_4s_c, y_4s_c = get_x_y_c(new_window_4s, new_neg_window_4s)\n",
        "X_5s_c, y_5s_c = get_x_y_c(new_window_5s, new_neg_window_5s)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sB2d4QNOsVbb"
      },
      "source": [
        "##### X, y for Distraction/Attention with different window size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1zgZaYushvI"
      },
      "outputs": [],
      "source": [
        "#X_0_2s, y_0_2s = get_x_y(window_0_2s, neg_window_0_2s)\n",
        "X_0_5s_d, y_0_5s_d = get_x_y_d(new_window_0_5s, new_neg_window_0_5s)\n",
        "X_1s_d, y_1s_d = get_x_y_d(new_window_1s, new_neg_window_1s)\n",
        "#X_1_5s, y_1_5s = get_x_y(window_1_5s, neg_window_1_5s)\n",
        "X_2s_d, y_2s_d = get_x_y_d(new_window_2s, new_neg_window_2s)\n",
        "#X_2_5s, y_2_5s = get_x_y(window_2_5s, neg_window_2_5s)\n",
        "X_3s_d, y_3s_d = get_x_y_d(new_window_3s, new_neg_window_3s)\n",
        "#X_3_5s, y_3_5s = get_x_y(window_3_5s, neg_window_3_5s)\n",
        "X_4s_d, y_4s_d = get_x_y_d(new_window_4s, new_neg_window_4s)\n",
        "X_5s_d, y_5s_d = get_x_y_d(new_window_5s, new_neg_window_5s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yC6rS7G7vTD3"
      },
      "outputs": [],
      "source": [
        "# Define a function to save X and y as CSV files\n",
        "def save_x_y_as_csv(X, y, X_filename, y_filename):\n",
        "    X_df = pd.DataFrame(X)\n",
        "    y_df = pd.DataFrame(y)\n",
        "\n",
        "    X_df.to_csv(X_filename, index=False)\n",
        "    y_df.to_csv(y_filename, index=False)\n",
        "\n",
        "\n",
        "save_x_y_as_csv(X_0_5s_c, y_0_5s_c, 'X_0_5s_c.csv', 'y_0_5s_c.csv')\n",
        "save_x_y_as_csv(X_1s_c, y_1s_c, 'X_1s_c.csv', 'y_1s_c.csv')\n",
        "save_x_y_as_csv(X_2s_c, y_2s_c, 'X_2s_c.csv', 'y_2s_c.csv')\n",
        "save_x_y_as_csv(X_3s_c, y_3s_c, 'X_3s_c.csv', 'y_3s_c.csv')\n",
        "save_x_y_as_csv(X_4s_c, y_4s_c, 'X_4s_c.csv', 'y_4s_c.csv')\n",
        "save_x_y_as_csv(X_5s_c, y_5s_c, 'X_5s_c.csv', 'y_5s_c.csv')\n",
        "\n",
        "save_x_y_as_csv(X_0_5s_d, y_0_5s_d, 'X_0_5s_d.csv', 'y_0_5s_d.csv')\n",
        "save_x_y_as_csv(X_1s_d, y_1s_d, 'X_1s_d.csv', 'y_1s_d.csv')\n",
        "save_x_y_as_csv(X_2s_d, y_2s_d, 'X_2s_d.csv', 'y_2s_d.csv')\n",
        "save_x_y_as_csv(X_3s_d, y_3s_d, 'X_3s_d.csv', 'y_3s_d.csv')\n",
        "save_x_y_as_csv(X_4s_d, y_4s_d, 'X_4s_d.csv', 'y_4s_d.csv')\n",
        "save_x_y_as_csv(X_5s_d, y_5s_d, 'X_5s_d.csv', 'y_5s_d.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
