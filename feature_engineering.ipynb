{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "####import packages"
      ],
      "metadata": {
        "id": "PeFmnavkFDBU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJLGPvokcpur"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, SGDClassifier, LogisticRegression\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, roc_auc_score, precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module=\"my_module\")\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('merged_df(window size 0.04 approximately) (3).csv')\n",
        "replacement_dict = {'Saccade': 0, 'Fixation': 1, 'Unclassified': 2, 'EyesNotFound': 3}\n",
        "\n",
        "# Replace the values in the column\n",
        "df['Eye movement type'] = df['Eye movement type'].replace(replacement_dict)\n",
        "\n",
        "feature_names = ['Gaze event duration', 'Fixation point X',\n",
        "       'Fixation point Y', 'Eye movement type', 'Accelerometer X',\n",
        "       'Accelerometer Y', 'Accelerometer Z', 'Gyro X', 'Gyro Y', 'Gyro Z',\n",
        "       'Gaze point X', 'Gaze point Y', 'Gaze point 3D X', 'Gaze point 3D Y',\n",
        "       'Gaze point 3D Z', 'Gaze direction left X', 'Gaze direction left Y',\n",
        "       'Gaze direction left Z', 'Gaze direction right X',\n",
        "       'Gaze direction right Y', 'Gaze direction right Z',\n",
        "       'Pupil position left X', 'Pupil position left Y',\n",
        "       'Pupil position left Z', 'Pupil position right X',\n",
        "       'Pupil position right Y', 'Pupil position right Z',\n",
        "       'Pupil diameter left', 'Pupil diameter right']\n",
        "X = df[feature_names]\n",
        "imputer = SimpleImputer()\n",
        "X_filled = imputer.fit_transform(X)\n",
        "X_filled = pd.DataFrame(X_filled, columns=feature_names)\n",
        "X_filled['Time Window'] = df['Time Window']\n",
        "X_filled['is_distraction'] = df['is_distraction']\n",
        "X_filled['videoNum'] = df['videoNum']\n",
        "X_filled['Participant ID'] = df['Participant ID']\n",
        "X_filled['order'] = df['order']\n",
        "X_filled['interest_level'] = df['interest_level']\n",
        "\n",
        "\n",
        "X_filled = X_filled[X_filled['Time Window'].notna()]"
      ],
      "metadata": {
        "id": "5VjF08wFdKUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_data(df, window_size, include = True):\n",
        "### THE function for data window parsing\n",
        "### return 1) parsed window contains EITHER distraction or attention\n",
        "### return 2) parsed window contains neigher distraction nor attention, and not overlap with 1)\n",
        "\n",
        "\n",
        "  all_windows = [] # windows for verbolization\n",
        "  all_windows_neg = []\n",
        "  tracked = False\n",
        "  last_time = None\n",
        "  last_index = -1\n",
        "  videoN = -1\n",
        "  for index, row in df.iloc[::-1].iterrows():\n",
        "    if tracked ==True:\n",
        "      # print('Here')\n",
        "      if row['is_distraction']!='None' or row['videoNum']!=videoN:\n",
        "        res = row['Time Window'].strip('][').split(', ')\n",
        "        # print(last_time, float(res[0]))\n",
        "        if ((last_time - float(res[0])) <= window_size):\n",
        "          if include and (last_index-index>3):\n",
        "            all_windows.append(df.iloc[index+1:last_index+2].copy())\n",
        "        last_time = float(res[1])\n",
        "        last_index = index\n",
        "        if row['videoNum']!=videoN and row['is_distraction']=='None':\n",
        "          tracked=False\n",
        "          # print(1, last_time-float(res[0]))\n",
        "          # print('find a window')\n",
        "        videoN = row['videoNum']\n",
        "      elif row['is_distraction']=='None':\n",
        "        res = row['Time Window'].strip('][').split(', ')\n",
        "        if row['videoNum']!=videoN:\n",
        "          tracked = False\n",
        "          last_index = index\n",
        "          videoN = row['videoNum']\n",
        "        if (last_time - float(res[0])) > window_size:\n",
        "          all_windows.append(df.iloc[index+1:last_index+1].copy())\n",
        "          tracked = False\n",
        "          last_index = index\n",
        "          videoN = row['videoNum']\n",
        "          # print(2, last_time-float(res[0]))\n",
        "\n",
        "          # print('find a window')\n",
        "    else:\n",
        "      if row['is_distraction']!='None':\n",
        "        # print('window')\n",
        "        res = row['Time Window'].strip('][').split(', ')\n",
        "        tracked = True\n",
        "        last_time = float(res[1])\n",
        "        all_windows_neg.append(df.iloc[index+1:last_index])\n",
        "        last_index = index\n",
        "        videoN = row['videoNum']\n",
        "\n",
        "  ## negation of window data\n",
        "  finite_all_windows_neg = []\n",
        "  for wind in all_windows_neg:\n",
        "    if wind.shape[0]>0:\n",
        "      start_time = float(wind.iloc[0]['Time Window'].strip('][').split(', ')[0])\n",
        "      for index, row in wind.iterrows():\n",
        "        t = float(row['Time Window'].strip('][').split(', ')[1])\n",
        "        if (t-start_time)>=window_size:\n",
        "          finite_all_windows_neg.append(wind.loc[0:index-1].copy())\n",
        "          break\n",
        "  print(len(all_windows), len(finite_all_windows_neg))\n",
        "  return all_windows, finite_all_windows_neg\n",
        "\n",
        "def parse_neg_data(df, window_size):\n",
        "  all_windows_neg=[]\n",
        "  start_index = df.shape[0]-1\n",
        "  start_time = float(df.iloc[start_index]['Time Window'].strip('][').split(', ')[1])\n",
        "  videoN = df.iloc[start_index]['videoNum']\n",
        "  for index, row in df.iloc[::-1].iterrows():\n",
        "    if row['is_distraction']!='None' or (videoN!=row['videoNum']):\n",
        "      start_index = index-1\n",
        "      start_time = float(df.iloc[start_index]['Time Window'].strip('][').split(', ')[1])\n",
        "    if ((start_time-float(df.iloc[index]['Time Window'].strip('][').split(', ')[0]))>window_size) and (start_index-index>3):\n",
        "      all_windows_neg.append(df.iloc[index+1:start_index+1].copy())\n",
        "      start_index = index\n",
        "      start_time = float(df.iloc[start_index]['Time Window'].strip('][').split(', ')[1])\n",
        "  return all_windows_neg\n",
        "\n",
        "def check_windows(parsed_df):\n",
        "  checked = False\n",
        "  for i, df in enumerate(parsed_df):\n",
        "    a, b = df[df['is_distraction']=='True'].shape\n",
        "    c, d = df[df['is_distraction']=='False'].shape\n",
        "    if a>0 and c>0:\n",
        "      print('Found Irregular Df:',i)\n",
        "      checked=True\n",
        "    if a==0 and c==0:\n",
        "      print('Found no label Df:',i)\n",
        "      checked=True\n",
        "  if not checked:\n",
        "    print('No irregular rows')\n",
        "\n",
        "def check_neg_windows(parsed_df, window_size, tol):\n",
        "  checked = False\n",
        "  for i, df in enumerate(parsed_df):\n",
        "    a, b = df[df['is_distraction']!='None'].shape\n",
        "    s = float(df.iloc[0]['Time Window'].strip('][').split(', ')[0])\n",
        "    e = float(df.iloc[-1]['Time Window'].strip('][').split(', ')[1])\n",
        "    if a>0:\n",
        "      print('Contains Distraction Data',i)\n",
        "      checked = True\n",
        "    if np.abs(window_size - (e-s)) > tol:\n",
        "      print('Inrregular Large Window',i)\n",
        "      checked = True\n",
        "  if not checked:\n",
        "      print('No irregular rows')"
      ],
      "metadata": {
        "id": "x0B45ZErdNIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Function"
      ],
      "metadata": {
        "id": "mmbTqwZqd2tX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#std\n",
        "def get_std_df(df_list, column_names):\n",
        "    std_list = []\n",
        "\n",
        "    for df in df_list:\n",
        "        std_row = []\n",
        "        for col in column_names:\n",
        "            std_row.append(np.std(df[col]))\n",
        "        std_list.append(std_row)\n",
        "\n",
        "    std_df = pd.DataFrame(std_list, columns=column_names)\n",
        "\n",
        "    return std_df\n"
      ],
      "metadata": {
        "id": "8NW-hNHcd0eQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sum\n",
        "def calculate_avg_a(df_list, column_names):\n",
        "    l1 = []\n",
        "    for df in df_list:\n",
        "        df = df.reset_index(drop=True)\n",
        "        a_list = []\n",
        "        for i in range(len(df[column_names[0]])):\n",
        "            if i > 0:\n",
        "                a = np.sqrt(np.square(df[column_names[0]][i] - df[column_names[0]][i-1]) \\\n",
        "                + np.square(df[column_names[1]][i] - df[column_names[1]][i-1]) \\\n",
        "                + np.square(df[column_names[2]][i] - df[column_names[2]][i-1]))\n",
        "                a_list.append(a)\n",
        "        sum_a = np.sum(a_list)\n",
        "        l1.append(sum_a)\n",
        "    return pd.DataFrame({'avg_a': l1})"
      ],
      "metadata": {
        "id": "98TSiI8Gd5r1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Saccade_fixation_ratio(df_list):\n",
        "    fixation_count = []\n",
        "    saccade_count = []\n",
        "\n",
        "    for df in df_list:\n",
        "\n",
        "        fixation = df[df['Eye movement type'] == 0]['Eye movement type'].count()\n",
        "        saccade = df[df['Eye movement type'] == 1]['Eye movement type'].count()\n",
        "\n",
        "        fixation_count.append(fixation/len(df))\n",
        "        saccade_count.append(saccade/len(df))\n",
        "\n",
        "    result = pd.DataFrame({'Fixation count': fixation_count, 'Saccade count': saccade_count})\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "25r9sskzd8K_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def absolute_changes(df_list, col_name):\n",
        "  max = 0\n",
        "  min = 0\n",
        "  a = 0\n",
        "  change = []\n",
        "  for df in df_list:\n",
        "    for i in df[col_name]:\n",
        "      if i < min:\n",
        "        min = i\n",
        "      elif i > max:\n",
        "        max = i\n",
        "    a = abs(max - min)\n",
        "    min = 0\n",
        "    max = 0\n",
        "    change.append(a)\n",
        "\n",
        "  return pd.DataFrame({'abs_change': change})"
      ],
      "metadata": {
        "id": "2pueuaSTd-P4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def avg_col(df_list, col_name):\n",
        "  y = []\n",
        "  a1 = []\n",
        "  for df in df_list:\n",
        "    for i in df[col_name]:\n",
        "      y.append(i)\n",
        "    average = abs(np.mean(y))\n",
        "    y = []\n",
        "    a1.append(average)\n",
        "  return pd.DataFrame({'avg1': a1})"
      ],
      "metadata": {
        "id": "UjhS2q2QeA8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def con_df(df1, df2, df3):\n",
        "  #concatenated = df1.join(df2)\n",
        "  concatenated = df1.join([df2, df3])\n",
        "  return concatenated"
      ],
      "metadata": {
        "id": "oXSaLwZEEAmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def longest_fixation(df_list1):\n",
        "    b = 0\n",
        "    c = 0\n",
        "    d = list(range(2390))\n",
        "    e = []\n",
        "    f = 0\n",
        "    a = []\n",
        "    b = 0\n",
        "    #fixation_range_container = []\n",
        "\n",
        "    for df in df_list1:\n",
        "        b += 1\n",
        "        #print(b)\n",
        "        last_index_label = df.index.max()\n",
        "        last_row = df.loc[last_index_label]\n",
        "        start_time = 0\n",
        "        fixation_range_container = []\n",
        "        for index, row in df.iterrows():\n",
        "            i = row['Eye movement type']\n",
        "            j = row['Time Window']\n",
        "\n",
        "            if i == 1 and not row.equals(last_row):\n",
        "                res = j.strip('][').split(', ')\n",
        "                last_time = float(res[1])\n",
        "                first_time = float(res[0])\n",
        "                if start_time == 0:\n",
        "                    start_time = first_time\n",
        "\n",
        "            if i != 1 and not row.equals(last_row):\n",
        "                res = j.strip('][').split(', ')\n",
        "                first_time_2 = float(res[0])\n",
        "                if start_time != 0:\n",
        "                    fixation_range_container.append(first_time_2 - start_time)\n",
        "                    start_time = 0\n",
        "\n",
        "            if row.equals(last_row):\n",
        "                if i == 1:\n",
        "                    res = j.strip('][').split(', ')\n",
        "                    last_time = float(res[1])\n",
        "                    first_time = float(res[0])\n",
        "                    if start_time == 0:\n",
        "                      fixation_range_container.append(last_time - first_time)\n",
        "\n",
        "                      start_time = 0\n",
        "                      #a.append(max(fixation_range_container))\n",
        "                      #e.append(len(a))\n",
        "                    else:\n",
        "                      fixation_range_container.append(last_time - start_time)\n",
        "                      #if b-1 == 53:\n",
        "                        #print(fixation_range_container)\n",
        "                      #print(b-1, fixation_range_container)\n",
        "                    a.append(max(fixation_range_container))\n",
        "                      #e.append(len(a))\n",
        "                    #if b-1 == 53:\n",
        "                      #print(a[-1])\n",
        "                    #print(index)\n",
        "                else:\n",
        "                    if start_time != 0:\n",
        "                      res = j.strip('][').split(', ')\n",
        "                      first_time_2 = float(res[0])\n",
        "                      fixation_range_container.append(first_time_2 - start_time)\n",
        "                      start_time = 0\n",
        "                      a.append(max(fixation_range_container))\n",
        "                      #e.append(len(a))\n",
        "                    elif len(fixation_range_container) == 0:\n",
        "                      a.append(0)\n",
        "                      #e.append(len(a))\n",
        "                    #print(index)\n",
        "                    elif len(fixation_range_container) != 0 and start_time == 0:\n",
        "                      a.append(max(fixation_range_container))\n",
        "\n",
        "\n",
        "\n",
        "        #e.append(len(a))\n",
        "    #demo = {'ColumnA': e, 'ColumnB': d}\n",
        "    #demo_df = pd.DataFrame(demo)\n",
        "    data = {'ColumnA': a}\n",
        "    lg_df = pd.DataFrame(data)\n",
        "    return lg_df\n"
      ],
      "metadata": {
        "id": "SUgtsAK7eOiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def verbalization_lag(df_list1):\n",
        "    c = 0\n",
        "    d = list(range(2390))\n",
        "    e = []\n",
        "    f = 0\n",
        "    a = []\n",
        "    b = 0\n",
        "    f_end = []\n",
        "    demo = []\n",
        "    # fixation_range_container = []\n",
        "\n",
        "    for df in df_list1:\n",
        "        b += 1\n",
        "        last_index_label = df.index.max()\n",
        "        last_row = df.loc[last_index_label]\n",
        "        start_time = 0\n",
        "        end_list = []\n",
        "        fixation_range_container = []\n",
        "        for index, row in df.iterrows():\n",
        "            i = row['Eye movement type']\n",
        "            j = row['Time Window']\n",
        "\n",
        "            if i == 1 and not row.equals(last_row):\n",
        "                res = j.strip('][').split(', ')\n",
        "                last_time = float(res[1])\n",
        "                first_time = float(res[0])\n",
        "                if start_time == 0:\n",
        "                    start_time = first_time\n",
        "\n",
        "            if i != 1 and not row.equals(last_row):\n",
        "                res = j.strip('][').split(', ')\n",
        "                first_time_2 = float(res[0])\n",
        "                if start_time != 0:\n",
        "                    fixation_range_container.append(first_time_2 - start_time)\n",
        "                    start_time = 0\n",
        "                    end_list.append(first_time_2)\n",
        "\n",
        "            if row.equals(last_row):\n",
        "                if i == 1:\n",
        "                    res = j.strip('][').split(', ')\n",
        "                    last_time = float(res[1])\n",
        "                    first_time = float(res[0])\n",
        "                    if start_time == 0:\n",
        "                        fixation_range_container.append(last_time - first_time)\n",
        "                        end_list.append(last_time)\n",
        "                        start_time = 0\n",
        "                        a.append(max(fixation_range_container))\n",
        "                    else:\n",
        "                        fixation_range_container.append(last_time - start_time)\n",
        "                        end_list.append(last_time)\n",
        "                        a.append(max(fixation_range_container))\n",
        "                else:\n",
        "                    if start_time != 0:\n",
        "                        res = j.strip('][').split(', ')\n",
        "                        first_time_2 = float(res[0])\n",
        "                        fixation_range_container.append(first_time_2 - start_time)\n",
        "                        end_list.append(first_time_2)\n",
        "                        start_time = 0\n",
        "                        a.append(max(fixation_range_container))\n",
        "                    elif len(fixation_range_container) == 0:\n",
        "                        a.append(0)\n",
        "                    elif len(fixation_range_container) != 0 and start_time == 0:\n",
        "                        a.append(max(fixation_range_container))\n",
        "\n",
        "        ind = fixation_range_container.index(max(fixation_range_container))\n",
        "        res = last_row['Time Window'].strip('][').split(', ')\n",
        "        start_p = float(res[0])\n",
        "        if start_p - end_list[ind] < 0:\n",
        "            f_end.append(start_p - end_list[ind] + max(fixation_range_container))\n",
        "        else:\n",
        "            f_end.append(start_p - end_list[ind] + max(fixation_range_container))\n",
        "\n",
        "    data = {'ColumnA': f_end}\n",
        "    lg_df = pd.DataFrame(data)\n",
        "    return lg_df"
      ],
      "metadata": {
        "id": "jf3elfg3eXF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Temporal_movement(df_list, col_names):\n",
        "    a = Saccade_fixation_ratio(df_list).reset_index(drop=True)\n",
        "    b = calculate_avg_a(df_list, col_names).reset_index(drop=True)\n",
        "    c = longest_fixation(df_list)\n",
        "    d = verbalization_lag(df_list)\n",
        "    result = pd.concat([a, b, c, d], axis=1, ignore_index=True)\n",
        "    result.columns = ['Fixation ratio', 'Saccade ratio', 'Trajectory Length Gaze', 'Longest Fixation range', 'verbalization lag']\n",
        "    return result\n",
        "\n",
        "\n",
        "def Gaze_pupil(df_list, col_names_1):\n",
        "    a = get_std_df(df_list, ['Fixation point X', 'Fixation point Y']).reset_index(drop=True)\n",
        "    b = avg_col(df_list, 'Fixation point X')\n",
        "    c = avg_col(df_list, 'Fixation point Y')\n",
        "    d = get_std_df(df_list, col_names_1).reset_index(drop=True)\n",
        "    e = absolute_changes(df_list, 'Gaze point 3D X').reset_index(drop=True)\n",
        "    f = absolute_changes(df_list, 'Gaze point 3D Y').reset_index(drop=True)\n",
        "    g = absolute_changes(df_list, 'Gaze point 3D Z').reset_index(drop=True)\n",
        "    h = avg_col(df_list, 'Gaze point 3D X').reset_index(drop=True)\n",
        "    i = avg_col(df_list, 'Gaze point 3D Y').reset_index(drop=True)\n",
        "    j = avg_col(df_list, 'Gaze point 3D Z').reset_index(drop=True)\n",
        "    k = get_std_df(df_list, ['Gaze point X', 'Gaze point Y']).reset_index(drop=True)\n",
        "    l = avg_col(df_list, 'Gaze point X').reset_index(drop=True)\n",
        "    m = avg_col(df_list, 'Gaze point Y').reset_index(drop=True)\n",
        "    n = get_std_df(df_list, ['Gaze direction left X', 'Gaze direction left Y', 'Gaze direction left Z']).reset_index(drop=True)\n",
        "    o = avg_col(df_list, 'Gaze direction left X').reset_index(drop=True)\n",
        "    p = avg_col(df_list, 'Gaze direction left Y').reset_index(drop=True)\n",
        "    q = avg_col(df_list, 'Gaze direction left Z').reset_index(drop=True)\n",
        "    r = get_std_df(df_list, ['Gaze direction right X', 'Gaze direction right Y', 'Gaze direction right Z']).reset_index(drop=True)\n",
        "    s = avg_col(df_list, 'Gaze direction right X').reset_index(drop=True)\n",
        "    t = avg_col(df_list, 'Gaze direction right Y').reset_index(drop=True)\n",
        "    u = avg_col(df_list, 'Gaze direction right Z').reset_index(drop=True)\n",
        "\n",
        "    v = get_std_df(df_list, ['Pupil position left X', 'Pupil position left Y', 'Pupil position left Z']).reset_index(drop=True)\n",
        "    w = avg_col(df_list, 'Pupil position left X').reset_index(drop=True)\n",
        "    x = avg_col(df_list, 'Pupil position left Y').reset_index(drop=True)\n",
        "    y = avg_col(df_list, 'Pupil position left Z').reset_index(drop=True)\n",
        "\n",
        "    z = get_std_df(df_list, ['Pupil position right X', 'Pupil position right Y', 'Pupil position right Z']).reset_index(drop=True)\n",
        "    z1 = avg_col(df_list, 'Pupil position right X').reset_index(drop=True)\n",
        "    z2 = avg_col(df_list, 'Pupil position right Y').reset_index(drop=True)\n",
        "    z3 = avg_col(df_list, 'Pupil position right Z').reset_index(drop=True)\n",
        "    z4 = get_std_df(df_list, ['Pupil diameter left', 'Pupil diameter right']).reset_index(drop=True)\n",
        "    z5 = avg_col(df_list, 'Pupil diameter left')\n",
        "    z6 = avg_col(df_list, 'Pupil diameter right')\n",
        "\n",
        "    result = pd.concat([a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z, z1, z2, z3, z4, z5, z6], axis=1, ignore_index=True)\n",
        "    new_name = ['SD of Fixation point X', 'SD of Fixation point Y', 'avg of Fixation point X', 'avg of Fixation point Y', \\\n",
        "                'SD of Gaze point 3D X', 'SD of Gaze point 3D Y', 'SD of Gaze point 3D Z', 'Abs change of Gaze point 3D X', 'Abs change of Gaze point 3D Y', 'Abs change of Gaze point 3D Z',\\\n",
        "                'avg of Gaze point 3D X', 'avg of Gaze point 3D Y', 'avg of Gaze point 3D Z',\\\n",
        "                'SD of Gaze point X', 'SD of Gaze point Y', 'avg of Gaze point X', 'avg of Gaze point Y',\\\n",
        "                'SD of Gaze direction left X', 'SD of Gaze direction left Y', 'SD of Gaze direction left Z', 'avg of Gaze direction left X', 'avg of Gaze direction left Y', 'avg of Gaze direction left Z',\\\n",
        "                'SD of Gaze direction right X', 'SD of Gaze direction right Y', 'SD of Gaze direction right Z', 'avg of Gaze direction right X', 'avg of Gaze direction right Y', 'avg of Gaze direction right Z',\\\n",
        "                'SD of Pupil position left X', 'SD of Pupil position left Y', 'SD of Pupil position left Z',\\\n",
        "                'avg of Pupil position left X', 'avg of Pupil position left Y', 'avg of Pupil position left Z',\\\n",
        "                'SD of Pupil position right X', 'SD of Pupil position right Y', 'SD of Pupil position right Z',\\\n",
        "                'avg of Pupil position right X', 'avg of Pupil position right Y', 'avg of Pupil position right Z',\\\n",
        "                'SD of Pupil diameter left', 'SD of Pupil diameter right',\\\n",
        "                'avg of Pupil diameter left', 'avg of Pupil diameter right']\n",
        "    result.columns = new_name\n",
        "\n",
        "    return result\n",
        "\n",
        "def headmovement_orientation(df_list, col_names):\n",
        "    a = absolute_changes(df_list, 'Gyro X').reset_index(drop=True)\n",
        "    b = absolute_changes(df_list, 'Gyro Y').reset_index(drop=True)\n",
        "    c = absolute_changes(df_list, 'Gyro Z').reset_index(drop=True)\n",
        "    d = avg_col(df_list, 'Gyro X').reset_index(drop=True)\n",
        "    e = avg_col(df_list, 'Gyro Y').reset_index(drop=True)\n",
        "    f = avg_col(df_list, 'Gyro Z').reset_index(drop=True)\n",
        "    g = get_std_df(df_list, col_names).reset_index(drop=True)\n",
        "    h = calculate_avg_a(df_list, col_names).reset_index(drop=True)\n",
        "    i = get_std_df(df_list, ['Accelerometer X', 'Accelerometer Y', 'Accelerometer Z']).reset_index(drop=True)\n",
        "    j = avg_col(df_list, 'Accelerometer X').reset_index(drop=True)\n",
        "    k = avg_col(df_list, 'Accelerometer Y').reset_index(drop=True)\n",
        "    l = avg_col(df_list, 'Accelerometer Z').reset_index(drop=True)\n",
        "    m = calculate_avg_a(df_list, ['Accelerometer X', 'Accelerometer Y', 'Accelerometer Z']).reset_index(drop=True)\n",
        "    result = pd.concat([a, b, c, d, e, f, g, h, i, j, k, l, m], axis=1, ignore_index=True)\n",
        "    new_name = ['abs_gyro_x', 'abs_gyro_y', 'abs_gyro_z',\\\n",
        "                'avg of Gyro X', 'avg of Gyro Y', 'avg of Gyro Z',\\\n",
        "                 'SD of Gyro X', 'SD of Gyro Y', 'SD of Gyro Z', 'Trajectory Length Gyro',\\\n",
        "                'SD of Accelerometer X', 'SD of Accelerometer Y', 'SD of Accelerometer Z',\\\n",
        "                'avg of Accelerometer X', 'avg of Accelerometer Y', 'avg of Accelerometer Z', 'Trajectory Length Accelerometer']\n",
        "    result.columns = new_name\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "4_Xh5xrRDOaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_useless_window(df_list1, df_list2):\n",
        "  indexes_to_remove = []\n",
        "  indexes_to_remove_1 = []\n",
        "  a = longest_fixation(df_list1)\n",
        "  b = longest_fixation(df_list2)\n",
        "  for i in range(len(a['ColumnA'])):\n",
        "    if a['ColumnA'][i] == 0:\n",
        "      indexes_to_remove.append(i)\n",
        "  for i in range(len(b['ColumnA'])):\n",
        "    if b['ColumnA'][i] == 0:\n",
        "      indexes_to_remove_1.append(i)\n",
        "  new_window_2s = [df for i, df in enumerate(df_list1) if i not in indexes_to_remove]\n",
        "  new_neg_window_2s = [df for i, df in enumerate(df_list2) if i not in indexes_to_remove_1]\n",
        "  return new_window_2s, new_neg_window_2s\n"
      ],
      "metadata": {
        "id": "J6K1J1Mlecpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_1s, neg_window_1s = parse_data(X_filled, 1, include=False)\n",
        "window_2s, neg_window_2s = parse_data(X_filled, 2, include=False)\n",
        "window_3s, neg_window_3s = parse_data(X_filled, 3, include=False)\n",
        "window_4s, neg_window_4s = parse_data(X_filled, 4, include=False)\n",
        "window_5s, neg_window_5s = parse_data(X_filled, 5, include=False)\n",
        "window_0_5s, neg_window_0_5s = parse_data(X_filled, 0.5, include=False)"
      ],
      "metadata": {
        "id": "2n_MxzQxpsmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del neg_window_0_5s[2810:2833]"
      ],
      "metadata": {
        "id": "iLSvnyq8pwkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_window_1s, new_neg_window_1s = remove_useless_window(window_1s, neg_window_1s)\n",
        "new_window_2s, new_neg_window_2s = remove_useless_window(window_2s, neg_window_2s)\n",
        "new_window_3s, new_neg_window_3s = remove_useless_window(window_3s, neg_window_3s)\n",
        "new_window_4s, new_neg_window_4s = remove_useless_window(window_4s, neg_window_4s)\n",
        "new_window_5s, new_neg_window_5s = remove_useless_window(window_5s, neg_window_5s)\n",
        "new_window_0_5s, new_neg_window_0_5s = remove_useless_window(window_0_5s, neg_window_0_5s)"
      ],
      "metadata": {
        "id": "XXJikaZGpyvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####define response variable"
      ],
      "metadata": {
        "id": "dRrJHEzLsgbJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "interest level == nan 0\n",
        "\n",
        "interest level == 0 1\n",
        "\n",
        "interest level >= 1 2"
      ],
      "metadata": {
        "id": "28_sO-C7sYP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def response_cta(df_list1, df_list2):\n",
        "  a = []\n",
        "  for df in df_list1:\n",
        "    for i in df['interest_level']:\n",
        "      if i == 0:\n",
        "        a.append(1)\n",
        "      elif i >= 1:\n",
        "        a.append(2)\n",
        "  df2 = pd.DataFrame(a, columns=['Response'])\n",
        "  length2 = len(df_list2)\n",
        "  df3 = pd.DataFrame(0, index=range(length2), columns=['Response'])\n",
        "  df_concat = pd.concat([df2, df3])\n",
        "  df_concat = df_concat.reset_index(drop=True)\n",
        "  return df_concat"
      ],
      "metadata": {
        "id": "bIK0d_uJp02L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "distraction 1\n",
        "\n",
        "attention 2"
      ],
      "metadata": {
        "id": "TYVWDGlvsR5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def response_dis(df_list1, df_list2):\n",
        "  a = []\n",
        "  for df in df_list1:\n",
        "    for i in df['is_distraction']:\n",
        "      if i == 'False':\n",
        "        a.append(2)\n",
        "      elif i == 'True':\n",
        "        a.append(1)\n",
        "  df2 = pd.DataFrame(a, columns=['Response'])\n",
        "  length2 = len(df_list2)\n",
        "  df3 = pd.DataFrame(0, index=range(length2), columns=['Response'])\n",
        "  df_concat = pd.concat([df2, df3])\n",
        "  df_concat = df_concat.reset_index(drop=True)\n",
        "  return df_concat"
      ],
      "metadata": {
        "id": "YqjBMfjRsNuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###conduct X & y"
      ],
      "metadata": {
        "id": "AJg0QV8AEwgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_x_y_c(df1, df2):\n",
        "    a1 = Temporal_movement(df1, ['Gaze point 3D X', 'Gaze point 3D Y', 'Gaze point 3D Z'])\n",
        "    a2 = Temporal_movement(df2, ['Gaze point 3D X', 'Gaze point 3D Y', 'Gaze point 3D Z'])\n",
        "    b1 = Gaze_pupil(df1, ['Gaze point 3D X', 'Gaze point 3D Y', 'Gaze point 3D Z'])\n",
        "    b2 = Gaze_pupil(df2, ['Gaze point 3D X', 'Gaze point 3D Y', 'Gaze point 3D Z'])\n",
        "    c1 = headmovement_orientation(df1, ['Gyro X', 'Gyro Y', 'Gyro Z'])\n",
        "    c2 = headmovement_orientation(df2, ['Gyro X', 'Gyro Y', 'Gyro Z'])\n",
        "    X1 = con_df(a1, b1, c1)\n",
        "    X2 = con_df(a2, b2, c2)\n",
        "    X = pd.concat([X1, X2])\n",
        "    X = X.reset_index(drop=True)\n",
        "    y = response_cta(df1, df2)\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "XQe6KWrpEUyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_x_y_d(df1, df2):\n",
        "    a1 = Temporal_movement(df1, ['Gaze point 3D X', 'Gaze point 3D Y', 'Gaze point 3D Z'])\n",
        "    a2 = Temporal_movement(df2, ['Gaze point 3D X', 'Gaze point 3D Y', 'Gaze point 3D Z'])\n",
        "    b1 = Gaze_pupil(df1, ['Gaze point 3D X', 'Gaze point 3D Y', 'Gaze point 3D Z'])\n",
        "    b2 = Gaze_pupil(df2, ['Gaze point 3D X', 'Gaze point 3D Y', 'Gaze point 3D Z'])\n",
        "    c1 = headmovement_orientation(df1, ['Gyro X', 'Gyro Y', 'Gyro Z'])\n",
        "    c2 = headmovement_orientation(df2, ['Gyro X', 'Gyro Y', 'Gyro Z'])\n",
        "    X1 = con_df(a1, b1, c1)\n",
        "    X2 = con_df(a2, b2, c2)\n",
        "    X = pd.concat([X1, X2])\n",
        "    X = X.reset_index(drop=True)\n",
        "    y = response_dis(df1, df2)\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "n0AsDEF6Eg8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X_0_2s, y_0_2s = get_x_y(window_0_2s, neg_window_0_2s)\n",
        "X_0_5s_c, y_0_5s_c = get_x_y_c(new_window_0_5s, new_neg_window_0_5s)\n",
        "X_1s_c, y_1s_c = get_x_y_c(new_window_1s, new_neg_window_1s)\n",
        "#X_1_5s, y_1_5s = get_x_y(window_1_5s, neg_window_1_5s)\n",
        "X_2s_c, y_2s_c = get_x_y_c(new_window_2s, new_neg_window_2s)\n",
        "#X_2_5s, y_2_5s = get_x_y(window_2_5s, neg_window_2_5s)\n",
        "X_3s_c, y_3s_c = get_x_y_c(new_window_3s, new_neg_window_3s)\n",
        "#X_3_5s, y_3_5s = get_x_y(window_3_5s, neg_window_3_5s)\n",
        "X_4s_c, y_4s_c = get_x_y_c(new_window_4s, new_neg_window_4s)\n",
        "X_5s_c, y_5s_c = get_x_y_c(new_window_5s, new_neg_window_5s)"
      ],
      "metadata": {
        "id": "ouu-SosVEX80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X_0_2s, y_0_2s = get_x_y(window_0_2s, neg_window_0_2s)\n",
        "X_0_5s_d, y_0_5s_d = get_x_y_d(new_window_0_5s, new_neg_window_0_5s)\n",
        "X_1s_d, y_1s_d = get_x_y_d(new_window_1s, new_neg_window_1s)\n",
        "#X_1_5s, y_1_5s = get_x_y(window_1_5s, neg_window_1_5s)\n",
        "X_2s_d, y_2s_d = get_x_y_d(new_window_2s, new_neg_window_2s)\n",
        "#X_2_5s, y_2_5s = get_x_y(window_2_5s, neg_window_2_5s)\n",
        "X_3s_d, y_3s_d = get_x_y_d(new_window_3s, new_neg_window_3s)\n",
        "#X_3_5s, y_3_5s = get_x_y(window_3_5s, neg_window_3_5s)\n",
        "X_4s_d, y_4s_d = get_x_y_d(new_window_4s, new_neg_window_4s)\n",
        "X_5s_d, y_5s_d = get_x_y_d(new_window_5s, new_neg_window_5s)"
      ],
      "metadata": {
        "id": "a1zgZaYushvI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}